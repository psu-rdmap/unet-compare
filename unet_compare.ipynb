{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psu-rdmap/unet-compare/blob/main/unet_compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogB11jwrz2_t"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "1. Click *Open in Colab* at the top\n",
        "\n",
        "2. Save a copy of this notebook via *File* > *Save a copy in Drive*\n",
        "\n",
        "3. Go to [Google Drive](https://drive.google.com) and create a new folder called `data/`.\n",
        "\n",
        "4. Create your dataset with the structure shown in the *Training & Inference* section of GitHub repository and place it in `data/`.\n",
        "\n",
        "5. Navigate to the notebook copy and select the drop down menu next to *Connect* in the top-right. Select *Change runtime type*, choose an available GPU, and select *Save*. Connect to a runtime\n",
        "\n",
        "6. Run all cells in *Source*. Note, you will have to authorize mounting to Google Drive\n",
        "\n",
        "7. Open the *Training/Inference* section, set the configs using the information [here](https://github.com/psu-rdmap/unet-compare/tree/main/configs), and run all cells in this section\n",
        "\n",
        "8. Operation will begin and a results folder will be created in your Google Drive\n",
        "\n",
        "9. To run it again, repeat 5-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3y6pXwAzpfw"
      },
      "source": [
        "# Source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edA7kjp2pJbM"
      },
      "source": [
        "## Prepare Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMFRECvNFZd5",
        "outputId": "3e7212d3-cae0-4f25-f2df-96c51de52bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "Successfully installed keras-3.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras --upgrade # need Keras 3.6.0 due to bug with saving/loading utility in default version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D7TBTz_rPPT",
        "outputId": "c332283b-cb59-4d4b-96d1-0eb8d05cf039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2VTZfcqKdT-",
        "outputId": "a74babb2-046a-4d9e-ee0f-d48fe9c1c406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.8.0\n",
            "2.17.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Conv2DTranspose, MaxPooling2D, Concatenate\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "import datetime\n",
        "from glob import glob\n",
        "from os import mkdir, listdir, remove\n",
        "from os.path import join, split, splitext, isdir\n",
        "import shutil\n",
        "import random\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from keras import backend as K\n",
        "import gc\n",
        "import keras\n",
        "import json\n",
        "from keras.preprocessing.image import save_img\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from natsort import os_sorted\n",
        "from keras.models import load_model\n",
        "\n",
        "random.seed(229)\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "tf.random.set_seed(3051)\n",
        "\n",
        "print(keras.__version__)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYtRIYVaKgLl"
      },
      "source": [
        "## Checkers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8iIcDj1qKjzt"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This module handles all operations related to validating user inputs\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "\n",
        "def general(configs : dict):\n",
        "    \"\"\"\n",
        "    Checks configs that are general to all modes\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs defined in the JSON input file\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # set root as absolute path to unet-compare\n",
        "    configs.update({'root' : '/content/drive/MyDrive/'})\n",
        "\n",
        "\n",
        "    training_modes = ['Single', 'CrossVal', 'Inference']\n",
        "    if 'training_mode' not in configs:\n",
        "        configs.update({'training_mode' : 'Single'})\n",
        "    else:\n",
        "        assert configs['training_mode'] in training_modes, 'Provided training_mode is invalid. Choose from: {}, {}, {}'.format(*training_modes)\n",
        "\n",
        "\n",
        "    if 'dataset_prefix' not in configs:\n",
        "        configs.update({'dataset_prefix' : 'gb_1024'})\n",
        "    else:\n",
        "        assert type(configs['dataset_prefix']) == str, 'dataset_prefix must be a string'\n",
        "        data_path = os.path.join(configs['root'], 'data/', configs['dataset_prefix'])\n",
        "        assert os.path.isdir(data_path), 'No directory exists at {}'.format(data_path)\n",
        "\n",
        "\n",
        "def training(configs : dict):\n",
        "    \"\"\"\n",
        "    Checks configs that are specific to training modes single and cross validation\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs defined in the JSON input file with updates after general()\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    encoders = ['UNet', 'EfficientNetB7']\n",
        "    if 'encoder_name' not in configs:\n",
        "        configs.update({'encoder_name' : 'UNet'})\n",
        "    else:\n",
        "        assert configs['encoder_name'] in encoders, 'Provided encoder_name is invalid. Choose from: {}, {}'.format(*encoders)\n",
        "\n",
        "\n",
        "    decoders = ['UNet', 'UNet++']\n",
        "    if 'decoder_name' not in configs:\n",
        "        configs.update({'decoder_name' : 'UNet'})\n",
        "    else:\n",
        "        assert configs['decoder_name'] in decoders, 'Provided decoder_name is invalid. Choose from: {}, {}'.format(*decoders)\n",
        "\n",
        "\n",
        "    # vanilla UNet encoder needs filter numbers\n",
        "    if 'encoder_filters' not in configs:\n",
        "        configs.update({'encoder_filters' : [64, 128, 256, 512, 1024]})\n",
        "    else:\n",
        "        assert type(configs['encoder_filters']) == list, 'encoder_filters must be an array of 5 positive integers'\n",
        "        assert len(configs['encoder_filters']) == 5, 'encoder_filters must have 5 integers'\n",
        "        assert all([type(filters) == int for filters in configs['encoder_filters']]), 'encoder_filters must be integers'\n",
        "        assert all([filters > 0 for filters in configs['encoder_filters']]), 'encoder_filters must be positive'\n",
        "\n",
        "\n",
        "    if 'decoder_filters' not in configs:\n",
        "        configs.update({'decoder_filters' : [512, 256, 128, 64, 32]})\n",
        "    else:\n",
        "        assert type(configs['decoder_filters']) == list, 'decoder_filter must be an array of 5 positive integers'\n",
        "        assert len(configs['decoder_filters']) == 5, 'decoder_filter must have 4 integers'\n",
        "        assert all([type(filters) == int for filters in configs['decoder_filters']]), 'decoder_filter must be integers'\n",
        "        assert all([filters > 0 for filters in configs['decoder_filters']]), 'decoder_filter must be positive'\n",
        "\n",
        "\n",
        "    if ' freeze_backbone' not in configs:\n",
        "        configs.update({'freeze_backbone' : False})\n",
        "    else:\n",
        "        assert type(configs['batchnorm']) == bool, 'freeze_backbone must be true or false'\n",
        "\n",
        "\n",
        "    if 'image_ext' not in configs:\n",
        "        configs.update({'image_ext' : '.jpg'})\n",
        "    else:\n",
        "        assert type(configs['image_ext']) == str, 'image_ext must be a string'\n",
        "        assert configs['image_ext'][0] == '.', 'image_ext must start with \\'.\\''\n",
        "\n",
        "\n",
        "    if 'annotation_ext' not in configs:\n",
        "        configs.update({'annotation_ext' : '.png'})\n",
        "    else:\n",
        "        assert type(configs['annotation_ext']) == str, 'annotation_ext must be a string'\n",
        "        assert configs['annotation_ext'][0] == '.', 'annotation_ext must start with a .'\n",
        "\n",
        "\n",
        "    if 'learning_rate' not in configs:\n",
        "        configs.update({'learning_rate' : 1e-4})\n",
        "    else:\n",
        "        assert type(configs['learning_rate']) == float, 'learning_rate must be float between 0 and 1'\n",
        "        assert configs['learning_rate'] > 0, 'learning_rate must be float between 0 and 1'\n",
        "        assert configs['learning_rate'] < 1, 'learning_rate must be float between 0 and 1'\n",
        "\n",
        "\n",
        "    if 'l2_reg' not in configs:\n",
        "        configs.update({'l2_reg' : 0.0})\n",
        "    else:\n",
        "        assert type(configs['l2_reg']) == float, 'l2_reg must be a float between 0 (inclusive) and 1'\n",
        "        assert configs['l2_reg'] >= 0, 'l2_reg must be a float between 0 (inclusive) and 1'\n",
        "        assert configs['l2_reg'] < 1, 'l2_reg must be a float between 0 (inclusive) and 1'\n",
        "\n",
        "\n",
        "    if 'batch_size' not in configs:\n",
        "        configs.update({'batch_size' : 1})\n",
        "    else:\n",
        "        assert type(configs['batch_size']) == int, 'batch_size must be a positive integer'\n",
        "        assert configs['batch_size'] > 0, 'batch_size must be a positive integer'\n",
        "\n",
        "\n",
        "    if 'num_epochs' not in configs:\n",
        "        configs.update({'num_epochs' : 50})\n",
        "    else:\n",
        "        assert type(configs['num_epochs'] == int), 'num_epochs must be a positive integer'\n",
        "        assert configs['num_epochs'] > 0, 'num_epochs must be a positive integer'\n",
        "\n",
        "\n",
        "    if 'batchnorm' not in configs:\n",
        "        configs.update({'batchnorm' : False})\n",
        "    else:\n",
        "        assert type(configs['batchnorm']) == bool, 'batchnorm must be true or false'\n",
        "\n",
        "\n",
        "    if 'augment' not in configs:\n",
        "        configs.update({'augment' : True})\n",
        "    else:\n",
        "        assert type(configs['augment']) == bool, 'augment must be true or false'\n",
        "\n",
        "\n",
        "    if 'save_best_only' not in configs:\n",
        "        configs.update({'save_best_only' : True})\n",
        "    else:\n",
        "        assert type(configs['save_best_only']) == bool, 'save_best_only must be true or false'\n",
        "\n",
        "\n",
        "    if 'standardize' not in configs:\n",
        "        configs.update({'standardize' : False})\n",
        "    else:\n",
        "        assert type(configs['standardize']) == bool, 'standardize must be true or false'\n",
        "\n",
        "    now = datetime.datetime.now()\n",
        "    results_dir = 'results_' + configs['dataset_prefix'] + '_' + configs['training_mode'] + '_' + configs['encoder_name'] + '_' + configs['decoder_name'] + now.strftime('_(%Y-%m-%d)_(%H-%M-%S)')\n",
        "    results_dir = os.path.join(configs['root'], results_dir)\n",
        "    configs.update({'results' : results_dir})\n",
        "\n",
        "\n",
        "def single(configs : dict):\n",
        "    \"\"\"\n",
        "    Checks early stopping and val settings\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs defined in the JSON input file with updates after general() and training()\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    training(configs)\n",
        "\n",
        "\n",
        "    if 'early_stopping' not in configs:\n",
        "        configs.update({'early_stopping' : True})\n",
        "    else:\n",
        "        assert type(configs['early_stopping']) == bool, 'early_stopping must be true or false. Set to false if using cross validation'\n",
        "\n",
        "\n",
        "    if configs['early_stopping']:\n",
        "        if 'patience' not in configs:\n",
        "            configs.update({'patience' : 10})\n",
        "        else:\n",
        "            assert type(configs['patience']) == int, 'patience must be a positive integer'\n",
        "            assert configs['patience'] > 0, 'patience must be a positive integer'\n",
        "\n",
        "\n",
        "    if 'train' not in configs:\n",
        "        if 'val' not in configs: # train NO, val NO\n",
        "            configs.update({'auto_split' : True})\n",
        "            if 'val_hold_out' not in configs:\n",
        "                raise KeyError('val_hold_out must be provided if no val set is provided. It refers to the percentage of the data to hold out for validation')\n",
        "            else:\n",
        "                assert type(configs['val_hold_out'] == float), 'val_hold_out must be a decimal between 0 and 1'\n",
        "                assert configs['val_hold_out'] > 0, 'val_hold_out must be a decimal between 0 and 1'\n",
        "                assert configs['val_hold_out'] < 1, 'val_hold_out must be a decimal between 0 and 1'\n",
        "        else: # train NO, val YES\n",
        "            assert type(configs['val']) == list, 'val must be an array of strings'\n",
        "            assert len(configs['val']) > 0, 'At least one validation image filename must be provided if a validation set is provided'\n",
        "            assert all([type(fn) == str for fn in configs['val']]), 'All elements of the validation filename set must be strings'\n",
        "            configs.update({'auto_split' : False})\n",
        "            data_path = os.path.join(configs['root'], 'data/', configs['dataset_prefix'], 'images/')\n",
        "            train_fns = [os.path.splitext(fn)[0] for fn in os.listdir(data_path)]\n",
        "            for val_fn in configs['val']: train_fns.remove(val_fn)\n",
        "            assert len(train_fns) > 0, 'At least one image must be left over for the training set'\n",
        "            configs.update({'train' : train_fns})\n",
        "    else:\n",
        "        configs.update({'auto_split' : False})\n",
        "        assert type(configs['train']) == list, 'train must be an array of strings'\n",
        "        assert len(configs['train']) > 0, 'At least one training image filename must be provided'\n",
        "        assert all([type(fn) == str for fn in configs['train']]), 'All elements of the training filename set must be strings'\n",
        "        if 'val' not in configs: # train YES, val NO\n",
        "            data_path = os.path.join(configs['root'], 'data/', configs['dataset_prefix'], 'images/')\n",
        "            val_fns = [os.path.splitext(fn)[0] for fn in os.listdir(data_path)]\n",
        "            for train_fn in configs['train']: val_fns.remove(train_fn)\n",
        "            assert len(val_fns) > 0, 'At least one image must be left over for the validation set'\n",
        "            configs.update({'val' : val_fns})\n",
        "        else: # train YES, val YES\n",
        "            assert type(configs['val']) == list, 'val must be an array of strings'\n",
        "            assert len(configs['val']) > 0, 'At least one validation image filename must be provided if a validation set is provided'\n",
        "            assert all([type(fn) == str for fn in configs['val']]), 'All elements of the validation filename set must be strings'\n",
        "            assert all([val_fn not in configs['train'] for val_fn in configs['val']]), 'Validation filename detected in training set'\n",
        "\n",
        "\n",
        "    if 'checkpoint_path' in configs:\n",
        "        assert type(configs['checkpoint_path']) == str, 'If continuing training from a previous model, checkpoint_path must be a path like string to the model .keras file. It should be relative to root'\n",
        "        model_path = os.path.join(configs['root'], configs['checkpoint_path'])\n",
        "        assert os.path.exists(model_path), 'Model file does not exist at {}'.format(model_path)\n",
        "        configs['checkpoint_path'] = model_path\n",
        "    else:\n",
        "        configs.update({'checkpoint_path' : None})\n",
        "\n",
        "\n",
        "def cross_val(configs : dict):\n",
        "    \"\"\"\n",
        "    Checks val settings and for number of folds\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs defined in the JSON input file with updates after general() and training()\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Updated configs : dict\n",
        "    \"\"\"\n",
        "\n",
        "    training(configs)\n",
        "\n",
        "    configs.update({'early_stopping' : False})\n",
        "    configs.update({'auto_split' : False})\n",
        "    configs.update({'checkpoint_path' : None})\n",
        "    assert 'val' not in configs, 'Do not provide a validation set, if using cross-validation'\n",
        "\n",
        "\n",
        "    if 'train' not in configs:\n",
        "        data_path = os.path.join(configs['root'], 'data/', configs['dataset_prefix'], 'images/')\n",
        "        assert os.path.isdir(data_path), 'Attempted to get retrieve filenames from {}, but the directory does not exist'.format(data_path)\n",
        "        train_filenames = [os.path.splitext(fn)[0] for fn in os.listdir(data_path)]\n",
        "        configs.update({'train' : train_filenames})\n",
        "    else:\n",
        "        assert type(configs['train']) == list, 'train must be an array of strings'\n",
        "        assert len(configs['train']) > 0, 'At least one training image filename must be provided'\n",
        "        assert all([type(fn) == str for fn in configs['train']]), 'All elements of the training filename set must be strings'\n",
        "\n",
        "\n",
        "    if 'num_folds' not in configs:\n",
        "        configs.update({'num_folds' : 3})\n",
        "    else:\n",
        "        assert type(configs['num_folds']) == int, 'num_folds must be a positive integer greater than 1'\n",
        "        assert configs['num_folds'] > 1, 'num_folds must be a positive integer greater than 1'\n",
        "        assert len(configs['train']) >= configs['num_folds'], 'There must be at least as many images as folds'\n",
        "\n",
        "\n",
        "def inference(configs : dict):\n",
        "    \"\"\"\n",
        "    Checks for model file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs defined in the JSON input file with updates after general()\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Updated configs : dict\n",
        "    \"\"\"\n",
        "\n",
        "    if 'model_path' not in configs:\n",
        "        raise KeyError('model_path not provided. It must be a path like string to the model file relative to root')\n",
        "    else:\n",
        "        assert type(configs['model_path']) == str, 'model_path must be a path like string to the .keras model file. It should be relative to root'\n",
        "        model_path = os.path.join(configs['root'], configs['model_path'])\n",
        "        assert os.path.exists(model_path), 'Model file does not exist at {}'.format(model_path)\n",
        "        configs['model_path'] = model_path\n",
        "\n",
        "    now = datetime.datetime.now()\n",
        "    results_dir = 'results_' + configs['dataset_prefix'] + '_' + configs['training_mode'] + now.strftime('_(%Y-%m-%d)_(%H-%M-%S)')\n",
        "    results_dir = os.path.join(configs['root'], results_dir)\n",
        "    configs.update({'results' : results_dir})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92NVEcYAKbd_"
      },
      "source": [
        "## Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E6Z4J7efKaN3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This module handles the definition of the custom convolution layers used in UNet models\n",
        "\"\"\"\n",
        "\n",
        "def ConvBlock(inputs, filters, batchnorm, l2_reg, index):\n",
        "    \"\"\"\n",
        "    Two Conv2D with optional batchnorm layer and ReLU activation\n",
        "    \"\"\"\n",
        "    def ConvUnit(inputs, layer_index):\n",
        "        x = Conv2D(filters, 3, padding='same', name='conv_'+layer_index, use_bias=not(batchnorm), kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg))(inputs)\n",
        "        if batchnorm:\n",
        "            x = BatchNormalization(name='bn_'+layer_index)(x)\n",
        "        return Activation('relu', name='relu_'+layer_index)(x)\n",
        "\n",
        "    x = ConvUnit(inputs, index+'a')\n",
        "    return ConvUnit(x, index+'b')\n",
        "\n",
        "\n",
        "def UpsampleBlock(inputs, filters, batchnorm, l2_reg, index):\n",
        "    \"\"\"\n",
        "    A Conv2DTranspose layer for upsampling with optional batchnorm layer and ReLU activation\n",
        "    \"\"\"\n",
        "    x = Conv2DTranspose(filters, 2, padding='same', name='up_'+index, use_bias=not(batchnorm), kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), strides=2)(inputs)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization(name='bn_'+index)(x)\n",
        "    return Activation('relu', name='relu_'+index)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rr6ZvWOKpVN"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rj-B_wMpKqxe"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This module handles all operations related to the loading of data or creation of a training dataset\n",
        "\"\"\"\n",
        "\n",
        "def create_dataset(configs : dict) -> tuple[dict, int, int]:\n",
        "    \"\"\"\n",
        "    Create the training dataset and return a Tensorflow Dataset instance of it\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Dictionary containing all data necessary to find the data and build the dataset\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Training and validation Dataset instances : dict\n",
        "    Number of train steps : int\n",
        "    Number of val steps : int\n",
        "    \"\"\"\n",
        "\n",
        "    # create directory structure and remove previous dataset if it was never deleted\n",
        "    ds_path = join(configs['root'], 'dataset')\n",
        "    if isdir(ds_path):\n",
        "        shutil.rmtree(ds_path)\n",
        "    train_val_paths = create_dstree(ds_path)\n",
        "\n",
        "    # if auto_split is true, this function will split the data into train/val sets\n",
        "    split_data(configs)\n",
        "\n",
        "    # update input shape in configs for model definition\n",
        "    get_input_shape(configs)\n",
        "\n",
        "    # copy images into dataset directory\n",
        "    populate_dstree(configs)\n",
        "\n",
        "    # augment dataset\n",
        "    if configs['augment']:\n",
        "        augment_dataset(configs, train_val_paths['train_path'])\n",
        "\n",
        "    # create a Tensorflow Dataset object\n",
        "    return define_dataset(train_val_paths, configs)\n",
        "\n",
        "\n",
        "def create_dstree(dest : str) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    Create the directory tree given the top-dataset directory path\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dest : str\n",
        "        Desired path to dataset\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Full paths to image train and val sets : dict\n",
        "    \"\"\"\n",
        "\n",
        "    # define directories\n",
        "    image_dir = join(dest, 'images')\n",
        "    annotation_dir = join(dest, 'annotations')\n",
        "    image_train_dir = join(image_dir, 'train')\n",
        "    image_val_dir = join(image_dir, 'val')\n",
        "    annotation_train_dir = join(annotation_dir, 'train')\n",
        "    annotation_val_dir = join(annotation_dir, 'val')\n",
        "\n",
        "    # run through all directories defined in the function and make them\n",
        "    for _, dir in locals().items():\n",
        "        mkdir(dir)\n",
        "\n",
        "    return {\"train_path\" : image_train_dir, \"val_path\" : image_val_dir}\n",
        "\n",
        "\n",
        "def populate_dstree(configs : dict):\n",
        "    \"\"\"\n",
        "    Copy files from data directory to empty dataset tree\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs given by the user\n",
        "    \"\"\"\n",
        "\n",
        "    # file sets\n",
        "    train_images = [image + configs['image_ext'] for image in configs['train']]\n",
        "    val_images = [image + configs['image_ext'] for image in configs['val']]\n",
        "\n",
        "    train_annotations = [annotation + configs['annotation_ext'] for annotation in configs['train']]\n",
        "    val_annotations = [annotation + configs['annotation_ext'] for annotation in configs['val']]\n",
        "\n",
        "    # source directories\n",
        "    image_source = join(configs['root'], 'data/', configs['dataset_prefix'], 'images/')\n",
        "    annotation_source = join(configs['root'], 'data/', configs['dataset_prefix'], 'annotations/')\n",
        "\n",
        "    # dest directories\n",
        "    image_train_dest = join(configs['root'], 'dataset/images/train')\n",
        "    image_val_dest = join(configs['root'], 'dataset/images/val')\n",
        "\n",
        "    annotation_train_dest = join(configs['root'], 'dataset/annotations/train')\n",
        "    annotation_val_dest = join(configs['root'], 'dataset/annotations/val')\n",
        "\n",
        "    # populate directories\n",
        "    copy_files(train_images, image_source, image_train_dest)\n",
        "    copy_files(val_images, image_source, image_val_dest)\n",
        "\n",
        "    copy_files(train_annotations, annotation_source, annotation_train_dest)\n",
        "    copy_files(val_annotations, annotation_source, annotation_val_dest)\n",
        "\n",
        "\n",
        "def copy_files(files : list, source : str, dest : str):\n",
        "    \"\"\"\n",
        "    Copies all provided files from a source directory to a destination directory\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    files : list\n",
        "        Filenames in source directory to be copied\n",
        "    source : str\n",
        "        Path to current location of files\n",
        "    dest : str\n",
        "        Path to where files are to be copied to\n",
        "    \"\"\"\n",
        "\n",
        "    for f in files:\n",
        "        src = join(source, f)\n",
        "        shutil.copy(src, dest)\n",
        "\n",
        "\n",
        "def get_input_shape(configs : dict):\n",
        "    \"\"\"\n",
        "    Adds input shape to configs\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs given by the user\n",
        "    \"\"\"\n",
        "\n",
        "    data_path = join(configs['root'], 'data/', configs['dataset_prefix'], 'images/', configs['train'][0] + configs['image_ext'])\n",
        "    test_img = cv2.imread(data_path)\n",
        "    configs.update({'input_shape' : test_img.shape})\n",
        "\n",
        "\n",
        "def augment_dataset(configs : dict, image_train_path : str):\n",
        "    \"\"\"\n",
        "    Replace each image and annotation with eight geometric augmentations\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Dictionary with relevant data information (file extensions, etc.)\n",
        "    image_train_path : str\n",
        "        Full path to training images in created dataset directory\n",
        "    \"\"\"\n",
        "\n",
        "    # loop through training images (use glob to get full path to each image)\n",
        "    for img in glob(join(image_train_path, '*')):\n",
        "        # replace images in path with annotations and image extension to annotation extension\n",
        "        ann = re.sub('images', 'annotations', img)\n",
        "        ann = re.sub(configs['image_ext'], configs['annotation_ext'], ann)\n",
        "\n",
        "        # augment image and annotation\n",
        "        augment_single_image(img)\n",
        "        augment_single_image(ann)\n",
        "\n",
        "\n",
        "def augment_single_image(file_full_path : str):\n",
        "    \"\"\"\n",
        "    Performs and saves eight unique geometric transformations on a given image then deletes the original image\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    file_full_path : str\n",
        "        Absolute path to a given file\n",
        "    \"\"\"\n",
        "\n",
        "    # get file path pieces\n",
        "    path, fn_ext = split(file_full_path)\n",
        "    fn, ext = splitext(fn_ext)\n",
        "\n",
        "    # load file\n",
        "    file = cv2.imread(file_full_path)\n",
        "\n",
        "    # perform transformations on file\n",
        "    file_1 = file                                              # original\n",
        "    file_2 = cv2.rotate(file, cv2.ROTATE_90_CLOCKWISE)         # rot90\n",
        "    file_3 = cv2.rotate(file, cv2.ROTATE_180)                  # rot180\n",
        "    file_4 = cv2.rotate(file, cv2.ROTATE_90_COUNTERCLOCKWISE)  # rot270\n",
        "    file_5 = cv2.flip(file, 1)                                 # xflip\n",
        "    file_6 = cv2.flip(file_2, 1)                               # rot90 + xflip\n",
        "    file_7 = cv2.flip(file_2, 0)                               # rot90 + yflip\n",
        "    file_8 = cv2.flip(file_3, 1)                               # rot180 + xflip\n",
        "\n",
        "    # save augmentations\n",
        "    cv2.imwrite(join(path, fn + '_1' + ext), file_1)\n",
        "    cv2.imwrite(join(path, fn + '_2' + ext), file_2)\n",
        "    cv2.imwrite(join(path, fn + '_3' + ext), file_3)\n",
        "    cv2.imwrite(join(path, fn + '_4' + ext), file_4)\n",
        "    cv2.imwrite(join(path, fn + '_5' + ext), file_5)\n",
        "    cv2.imwrite(join(path, fn + '_6' + ext), file_6)\n",
        "    cv2.imwrite(join(path, fn + '_7' + ext), file_7)\n",
        "    cv2.imwrite(join(path, fn + '_8' + ext), file_8)\n",
        "\n",
        "    # remove original image and label\n",
        "    remove(file_full_path)\n",
        "\n",
        "\n",
        "def define_dataset(train_val_paths : dict, configs : dict) -> tuple[dict, int, int]:\n",
        "    \"\"\"\n",
        "    Use created dataset to define Tensorflow Dataset instances for the training and validation sets\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    train_val_paths : dict\n",
        "        A dictionary containing paths to dataset train/val directories (e.g. dataset/images/train)\n",
        "    configs : dict\n",
        "        Dictionary containing all data necessary to find the data and build the dataset\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dataset : dict\n",
        "        Dictionary of training and validation instantiated Dataset objects\n",
        "    train_steps : int\n",
        "        Number of steps to take when training for a single pass over all available training data\n",
        "    val_steps : int\n",
        "        Number of steps to take during evaluation of the validation set after an epoch has completed\n",
        "    \"\"\"\n",
        "\n",
        "    # get size of training and validation sets\n",
        "    train_size = len(listdir(train_val_paths['train_path']))\n",
        "    val_size = len(listdir(train_val_paths['val_path']))\n",
        "\n",
        "    # initialize Dataset objects with a list of filenames\n",
        "    train_dataset = tf.data.Dataset.list_files(train_val_paths['train_path'] + '/*' + configs['image_ext'])\n",
        "    val_dataset = tf.data.Dataset.list_files(train_val_paths['val_path'] + '/*' + configs['image_ext'])\n",
        "\n",
        "    # replace every image path in the training and validation directories with a loaded image and annotation pair\n",
        "    train_dataset = train_dataset.map(lambda x: parse_image(x, configs), num_parallel_calls=AUTOTUNE)\n",
        "    val_dataset = val_dataset.map(lambda x: parse_image(x, configs), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    if configs['standardize']:\n",
        "        # get statistics for standardization (only from train) and apply to each train/val image set\n",
        "        m, s = get_ds_stats(train_dataset)\n",
        "        train_dataset = train_dataset.map(lambda image, annotation : ((image - m) / s, annotation))\n",
        "        val_dataset = val_dataset.map(lambda image, annotation : ((image - m) / s, annotation))\n",
        "\n",
        "    BUFFER_SIZE = 48\n",
        "\n",
        "    # define dict to contain Dataset instances\n",
        "    dataset = {\"train\": train_dataset, \"val\": val_dataset}\n",
        "\n",
        "    # shuffle the training dataset and batch it\n",
        "    dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE)\n",
        "    dataset['train'] = dataset['train'].repeat()\n",
        "    dataset['train'] = dataset['train'].batch(configs['batch_size'])\n",
        "    dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    # batch the validation dataset\n",
        "    dataset['val'] = dataset['val'].repeat()\n",
        "    dataset['val'] = dataset['val'].batch(1)\n",
        "    dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    # determine number of steps to take in an epoch\n",
        "    train_steps = train_size // configs['batch_size']\n",
        "    val_steps = val_size // 1\n",
        "\n",
        "    return dataset, train_steps, val_steps\n",
        "\n",
        "\n",
        "def parse_image(img_path : tf.string, configs : dict) -> tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"\n",
        "    Load an image and its annotation then resize it and normalize it\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    img_path : tf.str\n",
        "        Path to a given image to be loaded\n",
        "    data_cfgs : dict\n",
        "        Dictionary containing all info necessary to load and pre-process an image\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Loaded image and annotation pair : tf.Tensor, tf.Tensor\n",
        "    \"\"\"\n",
        "\n",
        "    # read image and load it into 3 channels (pre-trained backbones require 3)\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "\n",
        "    # adjust path to lead to the corresponding annotation and load it\n",
        "    annotation_path = tf.strings.regex_replace(img_path, \"images\", \"annotations\")\n",
        "    annotation_path = tf.strings.regex_replace(annotation_path, configs['image_ext'], configs['annotation_ext'])\n",
        "    annotation = tf.io.read_file(annotation_path)\n",
        "    annotation = tf.image.decode_png(annotation, channels=1)\n",
        "\n",
        "    # convert tensor objects to floats and normalize images ([0,255] -> [0.0, 1.0])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    annotation = tf.cast(annotation, tf.float32) / 255.0\n",
        "\n",
        "    # return two Tensor objects with loaded image and annotation data\n",
        "    return image, annotation\n",
        "\n",
        "\n",
        "def get_ds_stats(dataset : tf.data.Dataset) -> tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"\n",
        "    Computes mean and standard deviation for standardization of grayscale images\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : tf.data.Dataset\n",
        "        Dataset object with image/annotation pairs as elements\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dataset mean and standard deviation for each channel : tf.Tensor, tf.Tensor\n",
        "    \"\"\"\n",
        "\n",
        "    img_count, mean, std = 0, tf.zeros(3), tf.zeros(3)\n",
        "\n",
        "    for image, __ in dataset:\n",
        "        mean += tf.math.reduce_mean(image, axis=[0,1])\n",
        "        std += tf.math.reduce_std(image, axis=[0,1])\n",
        "        img_count += 1\n",
        "\n",
        "    mean /= img_count\n",
        "    std /= img_count\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "def split_data(configs : dict):\n",
        "    \"\"\"\n",
        "    Add training and validation sets to configs if necessary\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Information required to generate training and validation sets\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    configs : dict\n",
        "        Updated configs w/ train/val sets\n",
        "    \"\"\"\n",
        "\n",
        "    # case 1: auto_split is on and training filenames are provided\n",
        "    if (configs['auto_split'] == True) and ('train' in configs):\n",
        "        # randomly select training and validation subsets\n",
        "        train_fns, val_fns = auto_split(configs['train'], configs['val_hold_out'])\n",
        "\n",
        "        # overwrite training filename list and add new val filename list\n",
        "        configs['train'] = train_fns\n",
        "        configs.update({'val' : val_fns})\n",
        "\n",
        "    # case 2: auto_split is on and no training filenames are provided\n",
        "    elif configs['auto_split'] == True:\n",
        "        # get fns from image file source\n",
        "        fns_path = join(configs['root'], 'data/', configs['dataset_prefix'], 'images/')\n",
        "        fns = listdir(fns_path)\n",
        "\n",
        "        fns = [splitext(split(fn)[1])[0] for fn in fns]\n",
        "\n",
        "        # randomly select training and validation subsets\n",
        "        train_fns, val_fns = auto_split(fns, configs['val_hold_out'])\n",
        "\n",
        "        # add train and val filename lists\n",
        "        configs.update({'train' : train_fns})\n",
        "        configs.update({'val' : val_fns})\n",
        "\n",
        "    # case 3: data is already split and provided by the user\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "\n",
        "def auto_split(fns : list, val_hold_out : dict) -> tuple[list, list]:\n",
        "    \"\"\"\n",
        "    Randomly select subsets of the fns list for training and validation\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    fns : list\n",
        "        List of filenames to be split\n",
        "    val_hold_out : dict\n",
        "        Fraction of files to be held out for validation\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    train_fns : list\n",
        "        Filenames to be used for training\n",
        "    val_fns : list\n",
        "        Filenames to be used for validation\n",
        "    \"\"\"\n",
        "\n",
        "    # shuffle images to prevent sequence bias\n",
        "    random.shuffle(fns)\n",
        "\n",
        "    # upper/lower bounds\n",
        "    train_lower = 0\n",
        "    train_upper = int(len(fns)*(1-val_hold_out))\n",
        "\n",
        "    val_lower = train_upper\n",
        "    val_upper = len(fns)\n",
        "\n",
        "    # define and return new filenames sets\n",
        "    train_fns = fns[train_lower : train_upper]\n",
        "    val_fns = fns[val_lower : val_upper]\n",
        "\n",
        "    return train_fns, val_fns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHDNKtUiF1RO"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4-fqc_OgK9Wh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This module handles the definition of encoder/decoder subnetworks and their connection\n",
        "\"\"\"\n",
        "\n",
        "def UNet(configs : dict):\n",
        "    \"\"\"\n",
        "    U-Net built with Functional API using either U-Net or EfficientNetB7 encoders and either U-Net or U-Net++ decoders\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs defined in the JSON input file\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Keras Functional model representing the UNet : tf.keras.Model\n",
        "    \"\"\"\n",
        "\n",
        "    enc_filters = configs['encoder_filters']\n",
        "    dec_filters = configs['decoder_filters']\n",
        "    batchnorm = configs['batchnorm']\n",
        "    l2_reg = configs['l2_reg']\n",
        "\n",
        "    input = keras.Input(shape = configs['input_shape'], name = 'main_input')\n",
        "\n",
        "    # encoder\n",
        "    if configs['encoder_name'] == 'UNet':\n",
        "        model_name = 'UNet'\n",
        "        x = input\n",
        "        enc_outputs = []\n",
        "        for idx, filters in enumerate(enc_filters):\n",
        "            name_idx = f'{idx}0'\n",
        "            # conv\n",
        "            x = ConvBlock(x, filters, batchnorm, l2_reg, name_idx)\n",
        "            enc_outputs.append(x)\n",
        "            # pool\n",
        "            if idx < 4:\n",
        "                x = MaxPooling2D(pool_size=2, name = 'pool_'+name_idx)(x)\n",
        "\n",
        "\n",
        "    elif configs['encoder_name'] == 'EfficientNetB7':\n",
        "        model_name = 'EfficientNet'\n",
        "        backbone = EfficientNetB7(include_top = False, weights = 'imagenet', input_tensor = input)\n",
        "\n",
        "        # freeze entire backbone or just batchnorm layers\n",
        "        if configs['freeze_backbone']:\n",
        "            for layer in backbone.layers:\n",
        "                layer.trainable = False\n",
        "        else:\n",
        "            for layer in backbone.layers:\n",
        "                if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "                    layer.trainable = False\n",
        "\n",
        "        enc_stages = ['stem_activation', 'block2g_add', 'block3g_add', 'block5j_add', 'block7d_add']\n",
        "        enc_outputs = [backbone.get_layer(stage).output for stage in enc_stages]\n",
        "\n",
        "\n",
        "    # decoder\n",
        "    enc_outputs.reverse()\n",
        "    if configs['decoder_name'] == 'UNet':\n",
        "        model_name += '-UNet'\n",
        "        x = enc_outputs[0]\n",
        "        for idx, filters in enumerate(dec_filters[:-1]):\n",
        "            name_idx = f'{3-idx}{idx+1}' # 31, 22, 13, 04\n",
        "            x = UpsampleBlock(x, dec_filters[idx], batchnorm, l2_reg, name_idx)\n",
        "            x = Concatenate(name='cat_'+name_idx)([x, enc_outputs[idx+1]])\n",
        "            x = ConvBlock(x, dec_filters[idx], batchnorm, l2_reg, name_idx)\n",
        "\n",
        "    elif configs['decoder_name'] == 'UNet++':\n",
        "        model_name += '-UNetpp'\n",
        "        prev_row_outs = [enc_outputs[0]]\n",
        "        for row in range(4): # number of rows\n",
        "            current_row_outs = [enc_outputs[row+1]]\n",
        "            for node in range(row+1): # 1, 2, 3, 4 nodes per row\n",
        "                name_idx = f'{3-row}{node+1}' # 31, 21, 22, 11, 12, 13, 01, 02, 03, 04\n",
        "                x = UpsampleBlock(prev_row_outs[node], dec_filters[row], batchnorm, l2_reg, name_idx)\n",
        "                x = Concatenate(name='cat_'+name_idx)([x] + current_row_outs[:(node+1)])\n",
        "                x = ConvBlock(x, dec_filters[row], batchnorm, l2_reg, name_idx)\n",
        "                current_row_outs.append(x)\n",
        "            prev_row_outs = current_row_outs\n",
        "\n",
        "    # final layers\n",
        "    if configs['encoder_name'] == 'EfficientNetB7':\n",
        "        x = UpsampleBlock(x, dec_filters[4], batchnorm, l2_reg, 'final') # upsamples back to original resolution\n",
        "    sigmoid = Conv2D(1, 1, activation='sigmoid', name='main_output', kernel_initializer='he_normal', padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
        "\n",
        "    return keras.Model(inputs=input, outputs=sigmoid, name = model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJVyGo6NKxpr"
      },
      "source": [
        "## Modes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gzd4sTPjKz40"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This module handles the training/inference process\n",
        "\"\"\"\n",
        "\n",
        "def single_mode(configs : dict):\n",
        "    \"\"\"\n",
        "    Runs a single epoch-based training loop\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs provided by the user\n",
        "    \"\"\"\n",
        "\n",
        "    # get dataset\n",
        "    print('\\nCreating dataset...')\n",
        "    dataset, train_steps, val_steps = create_dataset(configs)\n",
        "    print('\\nTraining images: ', configs['train'])\n",
        "    print('Validation images:', configs['val'])\n",
        "\n",
        "    # get model\n",
        "    print('\\nLoading model...')\n",
        "    if configs['checkpoint_path'] is not None:\n",
        "        model = keras.load_model(configs['checkpoint_path'])\n",
        "    else:\n",
        "        model = UNet(configs)\n",
        "        model.compile(optimizer = Adam(learning_rate=configs['learning_rate']), loss = 'binary_crossentropy', metrics = ['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "    callbacks = [\n",
        "        CSVLogger(join(configs['results'], 'metrics.csv'), separator=',', append=False),\n",
        "        ModelCheckpoint(join(configs['results'], 'best.model.keras'), verbose=1, save_best_only=configs['save_best_only'], save_weights_only=False)\n",
        "    ]\n",
        "    if configs['early_stopping']:\n",
        "        callbacks.append(EarlyStopping(patience = configs['patience']))\n",
        "\n",
        "    # training\n",
        "    print('\\nStarting training loop...\\n')\n",
        "    model.fit(\n",
        "        dataset['train'],\n",
        "        epochs=configs['num_epochs'],\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=val_steps,\n",
        "        validation_data=dataset['val'],\n",
        "        callbacks=callbacks,\n",
        "        verbose=1 # 1 = live progress bar, 2 = one line per epoch\n",
        "    )\n",
        "\n",
        "    # load model corresponding to minimum val loss\n",
        "    if configs['save_best_only']:\n",
        "        model = keras.saving.load_model(join(configs['results'], 'best.model.keras'))\n",
        "\n",
        "    # inferences train/val sets and save results into results\n",
        "    print('\\nInferencing image sets...')\n",
        "    inference_ds(configs, model)\n",
        "\n",
        "    # plot loss, precision, recall, and f1\n",
        "    print('\\nPlotting metrics...')\n",
        "    plot_results(configs)\n",
        "\n",
        "    # remove training dataset and clear memory\n",
        "    print('\\nCleaning up...')\n",
        "    shutil.rmtree(join(configs['root'], 'dataset'))\n",
        "    K.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    if configs['training_mode'] == 'Single':\n",
        "        print('\\nDone.')\n",
        "\n",
        "\n",
        "def cross_val_mode(configs : dict):\n",
        "    \"\"\"\n",
        "    Runs single training mode many times on different hold out sets\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs provided by the user\n",
        "    \"\"\"\n",
        "\n",
        "    # determine all training and val set combinations given the number of folds\n",
        "    train_sets, val_sets = create_folds(configs['train'], configs['num_folds'])\n",
        "\n",
        "    # save original results directory\n",
        "    top_level_results = configs['results']\n",
        "\n",
        "    # loop through folds\n",
        "    for fold in range(configs['num_folds']):\n",
        "        # update train/val sets\n",
        "        configs.update({'train' : train_sets[fold]})\n",
        "        configs.update({'val' : val_sets[fold]})\n",
        "\n",
        "        # create results directory for this fold\n",
        "        results_dir = 'fold_' + str(fold+1)\n",
        "        results_dir = join(configs['results'], results_dir)\n",
        "        configs.update({'results' : results_dir})\n",
        "        mkdir(results_dir)\n",
        "\n",
        "        print()\n",
        "        print('-'*30 + ' Fold {} '.format(fold+1) + '-'*30)\n",
        "\n",
        "        # train fold\n",
        "        single_mode(configs)\n",
        "\n",
        "        # reset results directory for next fold\n",
        "        configs.update({'results' : top_level_results})\n",
        "\n",
        "    # plot metrics over all folds\n",
        "    print('\\nPlotting CV Metrics...')\n",
        "    cv_plot_results(configs)\n",
        "\n",
        "    configs.pop('val')\n",
        "\n",
        "    print('\\nDone.')\n",
        "\n",
        "\n",
        "def inference_mode(configs : dict):\n",
        "    \"\"\"\n",
        "    Feeds images into a trained model and saves predictions\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs provided by the user\n",
        "    \"\"\"\n",
        "\n",
        "    print('Loading images...')\n",
        "\n",
        "    # define path to images and retrieve filenames\n",
        "    data_path = join(configs['root'], 'data/', configs['dataset_prefix'])\n",
        "    ds_fns = listdir(data_path)\n",
        "\n",
        "    # create tensorflow ds\n",
        "    ds = [join(data_path, fn) for fn in ds_fns]\n",
        "    ds = tf.data.Dataset.from_tensor_slices(ds)\n",
        "    ds = ds.map(utils.parse_inference_image)\n",
        "\n",
        "    # build model and load weights\n",
        "    print('\\nLoading model...')\n",
        "    model = keras.saving.load_model(configs['model_path'])\n",
        "\n",
        "    # create and save predictions\n",
        "    print('\\nGenerating predictions and saving them...\\n')\n",
        "    preds = model.predict(ds, verbose=2)\n",
        "    save_fns = [join(configs['results'], split(fn)[0], '.png') for fn in ds_fns]\n",
        "    utils.save_preds(preds, save_fns)\n",
        "\n",
        "    print('\\nDone.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoSwtPN-LKd8"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z3tCnLzULQFs"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This module handles all accessory operations such as plotting and inference\n",
        "\"\"\"\n",
        "\n",
        "def parse_inference_image(img_path : str) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Given the full path to an image (/path/to/image.ext), load it into a tensor\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    img_path : str\n",
        "        Full path to image file\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Loaded image : tf.Tensor\n",
        "    \"\"\"\n",
        "\n",
        "    # read image and load it into 3 channels (pre-trained backbones require 3)\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "\n",
        "    # convert tensor objects to floats and normalize images ([0,255] -> [0.0, 1.0]) and return tensor\n",
        "    return tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "\n",
        "def save_preds(preds : tf.Tensor, save_fns : list):\n",
        "    \"\"\"\n",
        "    Save each prediction from a tensor of predictions\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    preds : tf.Tensor\n",
        "        Tensor of predictions with shape (N, H, W, 1) where N is the number of predictions\n",
        "    save_fns : list\n",
        "        List of corresponding image filenames\n",
        "    \"\"\"\n",
        "\n",
        "    for idx, pred in enumerate(preds):\n",
        "        save_img(save_fns[idx], pred)\n",
        "\n",
        "\n",
        "def inference_ds(configs : dict, model : tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Inferences and saves every training/validation image after training\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs given by the user\n",
        "    model : tf.keras.Model\n",
        "        Trained neural network\n",
        "    \"\"\"\n",
        "\n",
        "    data_path = os.path.join(configs['root'], 'data/', configs['dataset_prefix'], 'images/')\n",
        "\n",
        "    # define training and validation dataset\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices([data_path + img + configs['image_ext'] for img in configs['train']])\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices([data_path + img + configs['image_ext'] for img in configs['val']])\n",
        "\n",
        "    # replace every image path in the training and validation directories with a loaded image and annotation pair\n",
        "    train_ds = train_ds.map(parse_inference_image)\n",
        "    val_ds = val_ds.map(parse_inference_image)\n",
        "\n",
        "    # batch data\n",
        "    train_ds = train_ds.batch(1)\n",
        "    val_ds = val_ds.batch(1)\n",
        "\n",
        "    # get predictions\n",
        "    train_preds = model.predict(train_ds, verbose=1)\n",
        "    val_preds = model.predict(val_ds, verbose=1)\n",
        "\n",
        "    # define output directories\n",
        "    train_save_dir = os.path.join(configs['results'], 'train_preds')\n",
        "    os.mkdir(train_save_dir)\n",
        "    train_save_fns = [os.path.join(train_save_dir, fn + '.png') for fn in configs['train']]\n",
        "\n",
        "    val_save_dir = os.path.join(configs['results'], 'val_preds')\n",
        "    os.mkdir(val_save_dir)\n",
        "    val_save_fns = [os.path.join(val_save_dir, fn + '.png') for fn in configs['val']]\n",
        "\n",
        "    # save train and val preds\n",
        "    save_preds(train_preds, train_save_fns)\n",
        "    save_preds(val_preds, val_save_fns)\n",
        "\n",
        "\n",
        "def plot_results(configs : dict):\n",
        "    \"\"\"\n",
        "    Loads training metrics from a single training loop, plots them, and saves it into the results directory\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs given by the user\n",
        "    \"\"\"\n",
        "\n",
        "    # paths\n",
        "    metrics_path = os.path.join(configs['results'], 'metrics.csv')\n",
        "    plot_save_path = os.path.join(configs['results'], 'metrics.png')\n",
        "\n",
        "    # read metrics into dataframe\n",
        "    metrics = pd.read_csv(metrics_path)\n",
        "\n",
        "    # get num epochs, and redefine it offset by 1\n",
        "    num_epochs = metrics['epoch'].count()\n",
        "    metrics['epoch'] = metrics['epoch'] + 1\n",
        "\n",
        "    # determine lowest val loss index (where val loss is closest to min(val_loss))\n",
        "    best_idx = np.where(np.isclose(metrics['val_loss'], min(metrics['val_loss'])))[0]\n",
        "\n",
        "    # add f1 columns to the dataframe\n",
        "    metrics['f1'] = add_f1(metrics)\n",
        "    metrics['val_f1'] = add_f1(metrics, val = True)\n",
        "\n",
        "    # generate subplots\n",
        "    fig, axs = plt.subplots(4, 1, figsize=(12,20))\n",
        "\n",
        "    titles = ['BCE Loss', 'Precision', 'Recall', 'F1-Score']\n",
        "    y_axes = ['loss', 'Precision', 'Recall', 'f1']\n",
        "\n",
        "    for i in range(len(axs)):\n",
        "        y1 = y_axes[i]\n",
        "        y2 = 'val_' + y1\n",
        "\n",
        "        # plot metric curve\n",
        "        axs[i].plot(metrics['epoch'], metrics[y1], '-o',  label='Train')\n",
        "        axs[i].plot(metrics['epoch'], metrics[y2], '-o', label='Val')\n",
        "\n",
        "        # add point corresponding to lowest val loss on each curve\n",
        "        axs[i].plot(best_idx + 1, metrics[y1].iloc[best_idx], 'D', color='purple')\n",
        "        axs[i].plot(best_idx + 1, metrics[y2].iloc[best_idx], 'D', color='purple', label='Min Val Loss')\n",
        "\n",
        "        # misc settings\n",
        "        axs[i].set_xlabel('Epoch')\n",
        "        axs[i].set_ylabel(titles[i])\n",
        "        axs[i].set_xlim([1,num_epochs])\n",
        "        if i == 0:\n",
        "            axs[i].set_yscale('log')\n",
        "        else:\n",
        "            axs[i].set_yticks(ticks=np.arange(0,1.1,0.1))\n",
        "        axs[i].grid(visible=True)\n",
        "        axs[i].legend()\n",
        "\n",
        "    fig.savefig(plot_save_path, bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "def add_f1(metrics : pd.DataFrame, val = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates the f1-score element-wise given columns of the dataframe\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    metrics : pd.DataFrame\n",
        "        Metrics from the csv file made while training\n",
        "    val : bool\n",
        "        Whether the metrics correspond to the validation (true) or training (false) set\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    New metrics DataFrame column with f1 values : pd.DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    if val == True:\n",
        "        p = 'val_Precision'\n",
        "        r = 'val_Recall'\n",
        "    else:\n",
        "        p = 'Precision'\n",
        "        r = 'Recall'\n",
        "\n",
        "    # if the denominator is 0, then f1=0, otherwise it is the harmonic mean\n",
        "    return np.where(metrics[p] + metrics[r] == 0, 0, 2  * (metrics[p] * metrics[r]) / (metrics[p] + metrics[r]))\n",
        "\n",
        "\n",
        "def cv_plot_results(configs : dict):\n",
        "    \"\"\"\n",
        "    Loads in metrics for every fold, plots loss curves together, and plots statistics for each epoch\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    configs : dict\n",
        "        Input configs given by the user\n",
        "    \"\"\"\n",
        "\n",
        "    # paths\n",
        "    loss_save_path = os.path.join(configs['results'], 'loss.png')\n",
        "    metrics_save_path = os.path.join(configs['results'], 'metrics.png')\n",
        "\n",
        "    # get fold directory names and sort them using natural sorting\n",
        "    fold_dirs = glob(os.path.join(configs['results'], 'fold_*/'))\n",
        "    fold_dirs = os_sorted(fold_dirs)\n",
        "\n",
        "    # dict to hold dataframes for each fold\n",
        "    all_metrics = []\n",
        "    for fold in range(len(fold_dirs)):\n",
        "        # get metrics from csv\n",
        "        fold_metrics = pd.read_csv(os.path.join(fold_dirs[fold], 'metrics.csv'))\n",
        "\n",
        "        # add f1 columns to the dataframe\n",
        "        fold_metrics['f1'] = add_f1(fold_metrics)\n",
        "        fold_metrics['val_f1'] = add_f1(fold_metrics, val = True)\n",
        "\n",
        "        # convert to np array and add metrics array to list\n",
        "        fold_metrics_np = fold_metrics.to_numpy()\n",
        "        all_metrics.append(fold_metrics_np)\n",
        "\n",
        "    # stack all metrics arrays along a new 3d axis\n",
        "    all_metrics = np.stack(all_metrics, axis=0)\n",
        "\n",
        "    # get epochs list (always the same)\n",
        "    epochs = all_metrics[0, :, 0].astype(int) + 1\n",
        "\n",
        "    # plot loss curves together on two separate plots\n",
        "    fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "    for fold in range(configs['num_folds']):\n",
        "        # train/val losses\n",
        "        train_loss = all_metrics[fold, :, 4]\n",
        "        val_loss = all_metrics[fold, :, 8]\n",
        "\n",
        "        # plot losses\n",
        "        axs[0].plot(epochs, train_loss, label = 'Fold {}'.format(fold+1))\n",
        "        axs[1].plot(epochs, val_loss, label = 'Fold {}'.format(fold+1))\n",
        "\n",
        "    # formatting\n",
        "    axs[0].set_ylabel('Train Loss (BCE)')\n",
        "    axs[1].set_ylabel('Val Loss (BCE)')\n",
        "    for ax in axs:\n",
        "        ax.set_yscale('log')\n",
        "        ax.set_xlim([1, configs['num_epochs']])\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.grid(visible=True)\n",
        "        ax.legend()\n",
        "\n",
        "    fig.savefig(loss_save_path, bbox_inches=\"tight\")\n",
        "\n",
        "    # get mean and stdev across all folds\n",
        "    num_metrics = np.shape(all_metrics)[-1]\n",
        "    metrics_mean = np.zeros((configs['num_epochs'], num_metrics))\n",
        "    metrics_std = np.zeros((configs['num_epochs'], num_metrics))\n",
        "\n",
        "    for metric in range(num_metrics):\n",
        "        for epoch in range(configs['num_epochs']):\n",
        "            metrics_mean[epoch, metric] = np.mean(all_metrics[:, epoch, metric])\n",
        "            metrics_std[epoch, metric] = np.std(all_metrics[:, epoch, metric])\n",
        "\n",
        "    # plot averaged metrics with std as error bars\n",
        "    fig, axs = plt.subplots(4, 1, figsize=(12, 20))\n",
        "\n",
        "    # settings specific to each plot\n",
        "    titles = ['BCE Loss', 'Precision', 'Recall', 'F1-Score']\n",
        "    train_metrics_idcs = [4, 1, 2, 9]\n",
        "    val_metrics_idcs = [8, 5, 6, 10]\n",
        "\n",
        "    for i in range(len(axs)):\n",
        "        # means and stds\n",
        "        train_mean = metrics_mean[:, train_metrics_idcs[i]]\n",
        "        val_mean = metrics_mean[:, val_metrics_idcs[i]]\n",
        "\n",
        "        train_std = metrics_std[:, train_metrics_idcs[i]]\n",
        "        val_std = metrics_std[:, val_metrics_idcs[i]]\n",
        "\n",
        "        # plot mean\n",
        "        axs[i].errorbar(epochs, train_mean, yerr=train_std, fmt='-o', capsize=3, capthick=1, label='Train')\n",
        "        axs[i].errorbar(epochs, val_mean, yerr=val_std, fmt='-o', capsize=3, capthick=1, label='Val')\n",
        "\n",
        "        axs[i].set_xlabel('Epoch')\n",
        "        axs[i].set_ylabel(titles[i])\n",
        "        axs[i].set_xlim([1, configs['num_epochs']])\n",
        "        if i == 0:\n",
        "            axs[i].set_yscale('log')\n",
        "        else:\n",
        "            axs[i].set_yticks(ticks=np.arange(0,1.1,0.1))\n",
        "        axs[i].grid(visible=True)\n",
        "        axs[i].legend()\n",
        "\n",
        "    fig.savefig(metrics_save_path, bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "def create_folds(img_list : list, num_folds : int) -> tuple[list, list]:\n",
        "    \"\"\"\n",
        "    Given images and the number of folds, create training/validation sets with the most even distribution possible\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    img_list : list\n",
        "        List of filenames that will be used for cross-validation\n",
        "    num_folds : int\n",
        "        Number of training/validation sets to generate\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Training set for each fold : list\n",
        "    Validation set for each fold : list\n",
        "    \"\"\"\n",
        "\n",
        "    # number of validation images to be held out in each fold\n",
        "    num_val = np.zeros(num_folds)\n",
        "\n",
        "    # randomly shuffle the image list given a numpy seed to prevent sequence bias\n",
        "    np.random.seed(203)\n",
        "    img_list = np.random.permutation(img_list)\n",
        "\n",
        "    # determine number of hold out images in each fold\n",
        "    for i in range(num_folds):\n",
        "        # start with integer quotient\n",
        "        num_val[i] = math.floor(len(img_list) / num_folds)\n",
        "        # distribute the remainder evenly among the first folds\n",
        "        if i < (len(img_list) % num_folds):\n",
        "            num_val[i] += 1\n",
        "\n",
        "    # convert number of hold out images to indicies\n",
        "    running_sum = np.cumsum(num_val)\n",
        "    running_sum = np.insert(running_sum, 0, 0)\n",
        "    lower_idxs = running_sum[:-1].astype(int)\n",
        "    upper_idxs = running_sum[1:].astype(int)\n",
        "\n",
        "    # save train/val sets as elements of a list\n",
        "    train_sets, val_sets = [0]*num_folds, [0]*num_folds\n",
        "    for i in range(num_folds):\n",
        "        # bounds\n",
        "        low = lower_idxs[i]\n",
        "        up = upper_idxs[i]\n",
        "\n",
        "        # fold val set\n",
        "        val_sets[i] = img_list[low:up]\n",
        "\n",
        "        # fold train set is the complement\n",
        "        train_sets[i] = np.delete(img_list, np.arange(low, up)).tolist()\n",
        "\n",
        "    return train_sets, val_sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZPv83bNLBLp"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T-ma4KIcLDvR"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This module handles all preliminary operations for training including taking input from the user, checking it, and calling the correct mode function\n",
        "\"\"\"\n",
        "\n",
        "def print_input(configs : dict):\n",
        "    # create top-level results directory\n",
        "    mkdir(configs['results'])\n",
        "\n",
        "    # print input to user for confirmation\n",
        "    print('-'*50 + ' User Input ' + '-'*50)\n",
        "    for key, val in configs.items():\n",
        "        print(key + ':', val)\n",
        "    print('-'*112)\n",
        "\n",
        "def run(configs : dict):\n",
        "    # perform general checks on user input\n",
        "    print('\\nChecking user input...\\n')\n",
        "    general(configs)\n",
        "\n",
        "    # perform mode-specific checks on user input then run the chosen mode\n",
        "    if configs['training_mode'] == 'CrossVal':\n",
        "        cross_val(configs)\n",
        "        print_input(configs)\n",
        "        cross_val_mode(configs)\n",
        "\n",
        "    elif configs['training_mode'] == 'Inference':\n",
        "        inference(configs)\n",
        "        print_input(configs)\n",
        "        inference_mode(configs)\n",
        "\n",
        "    elif configs['training_mode'] == 'Single':\n",
        "        single(configs)\n",
        "        print_input(configs)\n",
        "        single_mode(configs)\n",
        "\n",
        "    # save configs into results dir for reference after mode runs\n",
        "    with open(join(configs['results'], 'configs.json'), 'w') as con:\n",
        "        json.dump(configs, con)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQftsPxzyju"
      },
      "source": [
        "# Training/Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZHt9P6vKMoKd"
      },
      "outputs": [],
      "source": [
        "# EfficientNet training (single loop)\n",
        "\n",
        "configs = {\n",
        "    \"training_mode\" : \"CrossVal\",\n",
        "    \"encoder_name\" : \"EfficientNetB7\",\n",
        "    \"freeze_backbone\" : False,\n",
        "    \"decoder_name\" : \"UNet\",\n",
        "    \"l2_reg\" : 0.0005,\n",
        "    \"num_epochs\" : 100,\n",
        "    \"num_folds\" : 5,\n",
        "    \"dataset_prefix\" : \"gb_512\",\n",
        "    \"batch_size\" : 4,\n",
        "    #\"val\" : [\"11_4\", \"1_2\", \"24_1\", \"4_2\", \"16_4\", \"14_4\", \"11_1\", \"30_1\", \"12_1\", \"1_3\", \"26_4\", \"30_4\", \"14_3\", \"31_4\", \"16_2\", \"4_1\", \"1_1\", \"7_3\", \"25_4\", \"30_3\", \"16_3\", \"14_1\", \"30_2\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GauK1-HnzSg4",
        "outputId": "b45b8631-95b2-4111-a396-41a4c9397e8c"
      },
      "outputs": [],
      "source": [
        "run(configs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOoeJIRxdjFNwdggYevVgWD",
      "collapsed_sections": [
        "V3y6pXwAzpfw",
        "4mQftsPxzyju"
      ],
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
